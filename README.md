# Motor & Visual Development Lab - VMIntegration
[![Python 3.7](https://img.shields.io/badge/python-3.7-blue.svg)](https://www.python.org/downloads/release/python-3710/)

This repository contains tools to open and spatially/temporally align data files recorded from mobile eye-tracking, camera-based motion-capture, and an immersive virtual environment and to generate visuomotor performance metrics.

The data used for the initial version of these tools were collected at the University of North Texas Health Science Center in the Human Movement Performance Lab and are now managed at the University of Michigan in the Motor & Visual Development Lab (http://kines.umich.edu/mvdlab) (PI: Dr. Haylie Miller) and analyzed in collaboration with the University of North Texas HILT Lab (http://hilt.cse.unt.edu/) (PI: Dr. Rodney Nielsen). Contributors to this project include Ian Zurutuza (@ianzur), Suleyman Olcay Polat (@sopolat), and Nicholas Fears (@nefears).

Sample data are located in this repository for the purpose of demonstration. The deidentified limited dataset used to develop these tools is available from Dr. Miller on reasonable request. Dr. Miller can be reached via email at millerhl@umich.edu.
